{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AskelaAsk/infr/blob/main/HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Dependencies management\n",
        "\n",
        "***git branch name:*** dependencies"
      ],
      "metadata": {
        "id": "VHdGmDRFnxwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theory [2]\n",
        "\n",
        "As usual, we will start with a few theoretical questions:\n",
        "\n",
        "* [0.5] What is Docker, and how it differs from dependencies management systems? From virtual machines?\n",
        "* [0.5] What are the advantages and disadvantages of using containers over other approaches?\n",
        "* [0.5] Explain how Docker works: what are Dockerfiles, how are containers created, and how are they run and destroyed?\n",
        "* [0.25] Name and describe at least one Docker competitor (i.e., a tool based on the same containerization technology).\n",
        "* [0.25] What is conda? How it differs from apt, yarn, and others?"
      ],
      "metadata": {
        "id": "mt6SsP_Ev4DQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem [6.5]\n",
        "\n",
        "The problem itself is relatively simple. \n",
        "\n",
        "Imagine that you developed an excellent RNA-seq analysis pipeline and want to share it with the world. Based on your experience, you are confident that the popularity of the pipeline will be proportional to its ease of use. So, you decided to help your future users and to pack all dependencies in a Conda environment and a Docker container.\n",
        "\n",
        "Here is the list of tools and their versions that are used in your work:\n",
        "* [fastqc](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/), v0.11.9\n",
        "* [STAR](https://github.com/alexdobin/STAR), v2.7.10b\n",
        "* [samtools](https://github.com/samtools/samtools), v1.16.1\n",
        "* [picard](https://github.com/broadinstitute/picard), v2.27.5\n",
        "* [salmon](https://github.com/COMBINE-lab/salmon), commit tag 1.9.0\n",
        "* [bedtools](https://github.com/arq5x/bedtools2), v2.30.0\n",
        "* [multiqc](https://github.com/ewels/MultiQC), v1.13\n"
      ],
      "metadata": {
        "id": "m--WCrL11SRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Anaconda**:\n",
        "\n",
        "* [1] Install conda, create a new virtual environment, and install all necessary packages. \n",
        "* [0.75] You won't be able to install some tools - that's fine. List their names, and explain what should be done to make them conda-friendly ([conda-forge](https://conda-forge.org/docs/maintainer/adding_pkgs.html) channel, [bioconda](https://bioconda.github.io/contributor/workflow.html) channel). \n",
        "* [0.25] [Export](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#exporting-the-environment-yml-file) the environment ([example](https://github.com/nf-core/clipseq/blob/master/environment.yml)) to the file and verify that it can be [rebuilt](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file) from the file without problems.\n",
        "\n"
      ],
      "metadata": {
        "id": "hehShsYn1Tv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Install conda\n",
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "id": "iOy-J3SoL7ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Добавляю каналы Forge && Bioconda\n",
        "%%bash\n",
        "conda install --channel defaults conda python=3.9 --yes\n",
        "conda update --channel defaults --all --yes\n",
        "conda update -n base -c defaults conda\n",
        "conda config --add channels defaults\n",
        "conda config --add channels bioconda\n",
        "conda config --add channels conda-forge\n",
        "conda config --set channel_priority strict"
      ],
      "metadata": {
        "id": "Az9CBXDQNF4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## init conda env\n",
        "%%bash\n",
        "conda create --name hw_env python=3.9\n",
        "conda activate hw_env"
      ],
      "metadata": {
        "id": "iXzuslBnNYYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install conda packages\n",
        "%%bash\n",
        "conda install -y star=2.7.10b  \n",
        "conda install -y samtools=1.16.1 \n",
        "conda install -y bedtools=2.30.0 \n",
        "conda install -y salmon=1.9.0\n",
        "conda install -y fastqc=0.11.9"
      ],
      "metadata": {
        "id": "XTA_3wTTNgIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install multiqc"
      ],
      "metadata": {
        "id": "Y0Vy_PPBN5VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "git clone -b 2.27.5 https://github.com/broadinstitute/picard.git\n",
        "cd picard\n",
        "./gradlew shadowJar\n",
        "java -jar build/libs/picard.jar\n",
        "./gradlew clean "
      ],
      "metadata": {
        "id": "DITSNBvcN0iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env export > hw_env.yml  "
      ],
      "metadata": {
        "id": "lM9G_DhfOGQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Docker**:\n",
        "* [3] Create a Dockerfile for a container with **all** required dependencies. Conda usage is not allowed, don't forget about comments; test that all tools are accessible and work inside the container. Hints:\n",
        " - If needed, grant rights to execute downloaded/compiled binaries using chmod (`chmod a+x BINARY_NAME`)\n",
        " - Move all executables to $PATH folders (e.g.`/usr/local/bin`) to make them accessible without specifying the full path.\n",
        " - Typical command to run a container interactively (`-it`) and delete on exit(`--rm`): `docker run --rm -it name:tag`\n",
        "* [1] Use [hadolint](https://hadolint.github.io/hadolint/) and remove as many reported warnings as possible.\n",
        "* [0.5] Add relevant [labels](https://docs.docker.com/engine/reference/builder/#label), e.g. maintainer, version, etc. ([hint](https://medium.com/@chamilad/lets-make-your-docker-image-better-than-90-of-existing-ones-8b1e5de950d))"
      ],
      "metadata": {
        "id": "pWDOph3xL61u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FROM ubuntu:18.04\n",
        "RUN useradd --create-home --shell /bin/bash app_user\n",
        "WORKDIR /home/app_user\n",
        "USER root\n",
        "RUN \tapt update\t&& \\\n",
        "\tapt-get update \t&& \\\n",
        "\tapt-get install -y wget && \t\\\n",
        "\tapt-get install -y make &&\t\\\n",
        "\tapt install -y openjdk-11-jdk &&\\\n",
        "\tapt-get install -y unzip &&\t\\\n",
        "\tapt-get install -y git \t&&\t\\\n",
        "\tapt-get install -y python3-pip\n",
        "\n",
        "# install fastqc rdy\n",
        "RUN  \techo 'FastQC installation process begin'\n",
        "RUN  \techo 'FastQC need java to run. So make sure u have it'\n",
        "RUN\t  wget https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.9.zip\n",
        "RUN  \tunzip fastqc_v0.11.9.zip && rm fastqc_v0.11.9.zip \n",
        "RUN   chmod a+x FastQC/fastqc\n",
        "RUN   echo 'alias fastqc=\"/FastQC/fastqc\"' >> /.bashrc\n",
        "RUN  \techo 'U can run it now with \"fastqc\" cmd in terminal'\n",
        "\n",
        "\n",
        "#install samtools rdy\n",
        "RUN \tgit clone -b 1.16.1 https://github.com/samtools/samtools.git\n",
        "RUN\t  mv samtools/misc samtools_tools && rm -R samtools \n",
        "RUN\t  echo 'alias samtools=\"/samtools_tools/samtools.pl\"' >> /.bashrc\n",
        "RUN\t  echo \"samtools installed\"\n",
        "\n",
        "#gradle done\n",
        "RUN \twget https://services.gradle.org/distributions/gradle-7.6-bin.zip\n",
        "RUN\t  mkdir /opt/gradle && unzip -d /opt/gradle gradle-7.6-bin.zip &&\\\n",
        "\t    rm gradle-7.6-bin.zip\n",
        "RUN\t  export PATH=$PATH:/opt/gradle/gradle-7.6/bin\n",
        "\n",
        "#picard rdy\n",
        "RUN\t  git clone -b 2.27.5 https://github.com/broadinstitute/picard.git\n",
        "RUN\t  cd picard/ && ./gradlew shadowJar\n",
        "RUN\t  echo 'alias picard=\"java -jar ./picard/bin/picard.jar\"' >> /.bashrc\n",
        "\n",
        "\n",
        "#salmon v.1.9.0\t\n",
        "RUN   wget https://github.com/COMBINE-lab/salmon/releases/download/v1.9.0/salmon-1.9.0_linux_x86_64.tar.gz \n",
        "RUN   tar -zxvf salmon-1.9.0_linux_x86_64.tar.gz && rm salmon-1.9.0_linux_x86_64.tar.gz \n",
        "RUN   chmod a+x salmon-1.9.0_linux_x86_64/bin/salmon && \\\n",
        "      mv salmon-1.9.0_linux_x86_64/bin/salmon /bin/salmon && \\\n",
        "      rm -r salmon-1.9.0_linux_x86_64 \n",
        "    \n",
        "#STAR v.2.7.10b\n",
        "RUN   wget https://github.com/alexdobin/STAR/releases/download/2.7.10b/STAR_2.7.10b.zip\n",
        "RUN   unzip STAR_2.7.10b.zip && rm STAR_2.7.10b.zip \n",
        "RUN   chmod a+x STAR_2.7.10b/Linux_x86_64_static/STAR\n",
        "RUN   mv STAR_2.7.10b/Linux_x86_64_static/STAR /bin/STAR && \\\n",
        "      rm -r STAR_2.7.10b\n",
        "\n",
        "\n",
        "RUN pip3 install --upgrade pip    \n",
        "RUN pip3 install multiqc==1.13"
      ],
      "metadata": {
        "id": "ELmlPfIGOVQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra points [1.5]\n",
        "\n",
        "You will be awarded extra points for the following:\n",
        "* [0.5] Using [multi-stage builds](https://docs.docker.com/build/building/multi-stage/) in Docker. E.g. to build STAR and copy only the executable to the final image.\n",
        "\n",
        "* [0.75] Minimizing the size of the final Docker image. That is, removing all intermediates, unnecessary binaries/caches, etc. Don't forget to compare & report the final size before and after all the optimizations.\n",
        "\n",
        "* [0.25] Create an extra Dockerfile that starts from [a conda base image](https://hub.docker.com/r/continuumio/anaconda3) and builds everything from your conda environment file. \n",
        "\n",
        "Hint: `conda env create --quiet -f environment.yml && conda clean -a` ([example](https://github.com/nf-core/clipseq/blob/master/Dockerfile))\n"
      ],
      "metadata": {
        "id": "k7BfQC_m1CFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Working with remote servers\n",
        "\n",
        "**git branch name:** jbrowser"
      ],
      "metadata": {
        "id": "N44WLnNn1gjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theory [2]\n",
        "\n",
        "* [0.4] What are [computer ports](https://www.cloudflare.com/learning/network-layer/what-is-a-computer-port/) on a high level? How many ports are there on a typical computer?\n",
        "* [0.4] What is the difference between http, https, ssh, and other protocols? In what sense are they similar? Name default ports for several data transfer protocols.\n",
        "* [0.4] Explain briefly: (1) what is IP, (2) what IPs are called 'white'/public, (3) and what happens when you enter 'google.com' into the web browser. \n",
        "* [0.4] What is Nginx? How does it work on the high level? List several alternative web servers.\n",
        "* [0.4] What is SSH, and for what is it typically used? Explain two ways to authenticate in an SSH server in detail."
      ],
      "metadata": {
        "id": "8t5OxUXc5VTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem [6.5]\n",
        "\n",
        "A real-life situation that occurred to me several times over the years.\n",
        "\n",
        "Imagine wrapping up a large bioinformatics project and wanting to share raw data with your colleagues in a friendly and straightforward format. The best option would be to use an online genome browser and host your data remotely, so it is easily accessible by anyone with a valid link. This is exactly what we will be doing here.\n",
        "\n",
        "*Please consider doing this HW using Linux since setting up the SSH client on Windows is painful, and I won't be able to help you.*"
      ],
      "metadata": {
        "id": "Kh5oUQSA5WxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remote Server**:\n",
        "* [2] Create a new virtual machine in the Yandex/Mail/etc cloud (order at least 10GB of free disk space). Generate SSH key pair and use it to connect to your server.\n",
        "* [1] Download the latest human genome assembly (GRCh38) from the Ensemble FTP server ([fasta](https://ftp.ensembl.org/pub/release-108/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz), [GFF3](https://ftp.ensembl.org/pub/release-108/gff3/homo_sapiens/Homo_sapiens.GRCh38.108.gff3.gz)). Index the fasta using samtools (`samtools faidx`) and GFF3 using tabix. \n",
        "* [1] Select and download BED files for three ChIP-seq and one ATAC-seq experiment from the ENCODE (use one tissue/cell line). Sort, bgzip, and index them using tabix.\n",
        "\n",
        "**JBrowse 2**\n",
        "* [1] Download and install [JBrowse 2](https://jbrowse.org/jb2/). Create a new jbrowse [repository](https://jbrowse.org/jb2/docs/cli/#jbrowse-create-localpath) in `/mnt/JBrowse/` (or some other folder).\n",
        "* [0.25] Install nginx and amend its config(/etc/nginx/nginx.conf) to contain the following section:\n",
        "```conf\n",
        "http {\n",
        "  # Don't touch other options!\n",
        "  # ........\n",
        "  # ........\n",
        "\n",
        "  # Comment this line(!):\n",
        "  # include /etc/nginx/sites-enabled/*;\n",
        "\n",
        "  # Add this:\n",
        "  server {\n",
        "    listen 80 default_server;\n",
        "    index index.html;\n",
        "    server_name _;\n",
        "\n",
        "    location /jbrowse/ {\n",
        "      alias /mnt/JBrowse/;\t\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "* [0.25] Restart the nginx (reload its config) and make sure that you can access the browser using a link like this: `http://64.129.58.13/jbrowse/`. Here `64.129.58.13` is your public IP address.\n",
        "* [1] Add your files (BED & FASTA & GFF3) to the genome browser and verify that everything works as intended. Don't forget to [index](https://jbrowse.org/jb2/docs/cli/#jbrowse-text-index) the genome annotation, so you could later search by gene names. Provide a [persistent link](https://jbrowse.org/jb2/docs/user_guides/basic_usage/#sharing-sessions) to a JBrowse 2 session with all your BED files and the genome annotation in the report (like [this](https://jbrowse.org/code/jb2/v2.3.1/?session=share-HShsEcnq3i&password=nYzTU)). *I must be able to access it without problems later.*\n",
        "\n",
        "\n",
        "**Common mistakes**:\n",
        "* Using `/home/username` folder for JBrowse. Don't do this - you will have permission issues (403 forbidden) because by default home is only available to your user, not to the nginx user(group).\n",
        "* No trailing `/` in the config (`/jbrowse/`, `/mnt/JBrowse/`), or in the URL (`http://64.129.58.13/jbrowse/`).\n",
        "* If you have added tracks but they are not showing up in JBrowse - try reloading the page or use a private/incognito window.\n",
        "* Don't use `sudo` when using JBrowse CLI: (1) you risk messing up with permissions, (2) you don't really need it.\n",
        "\n"
      ],
      "metadata": {
        "id": "6phPxd80OiLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sudo apt-get install wget \n",
        "sudo apt install gunzip samtools tabix\n",
        "mkdir genome_assembly\n",
        "cd genome_assembly\n",
        "wget ftp://ftp.ensembl.org/pub/release-99/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz\n",
        "gunzip Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz\n",
        "samtools faidx Homo_sapiens.GRCh38.dna.primary_assembly.fa\n",
        "cd "
      ],
      "metadata": {
        "id": "pfbZiB0QPgzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra points [1.5]\n",
        "\n",
        "* [1] Create a Docker container for running JBrowse 2. It should be a self-contained application, listening on the default HTTP port. Users must be able to mount directories with custom configs and access them later without any problems. \n",
        "\n",
        "Hint: to specify the config, use the config=PATH query parameter. E.g. `http://64.129.58.13/jbrowse/?config=my_folder%2Fconfig.json` where `my_folder%2Fconfig.json` is the [escaped](https://en.wikipedia.org/wiki/Percent-encoding) path to the config file.\n",
        "\n",
        "* [0.5] Give an in-depth explanation of the OSI model and how the TCP/IP stack works. Don't copy-paste descriptions from the internet; paraphrase and shorten as much as possible (imagine writing a cheat sheet for yourself).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "apXcKkvn5a_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Bioinformatic pipelines\n",
        "\n",
        "**git branch name:** bpipelines"
      ],
      "metadata": {
        "id": "EgA1n1GW15EE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theory [2]\n",
        "\n",
        "* [0.2] What is a pipeline (in bioinformatics)? Why are they so popular in bioinformatics and not in other areas?\n",
        "* [0.5] Explain how Snakemake and Nextflow work on the high level. I.e., what are their general paradigms?\n",
        "* [0.5] Name the most flexible and the least flexible way to organize a pipeline, and list their key advantages and disadvantages.\n",
        "* [0.8] Read the original [Snakemake](https://doi.org/10.1093/bioinformatics/bts480) and [Nextflow](https://doi.org/10.1038/nbt.3820) papers. What crucial problems the authors strived to solve?\n",
        "\n",
        "I also recommend to read [this](https://academic.oup.com/bib/article/18/3/530/2562749) excellent but somewhat outdated review of popular frameworks used to create bioinformatic pipelines."
      ],
      "metadata": {
        "id": "9u9zm8oo2A4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem [6.5]\n",
        "\n",
        "It's not possible and feasible to have an in-depth knowledge of all typical biological experiments, especially in your early career days. \n",
        "And a good strategy to deal with unknown experiments is to start with previously validated approaches, aka best practices. Nowadays, it is even easier, thanks to the development of publicly curated automatic pipelines.\n",
        "\n",
        "Our toy experiment for today is ChIP-seq, specifically ChIP for Myc transcription factor from a human cell line. We will analyze it using the public Nextflow [pipeline](https://github.com/nf-core/chipseq).\n",
        "\n",
        "* [1.5] Prerequisites: (1) download and install Nextflow, (2) download sequencing data for the first replica from [this](https://www.encodeproject.org/experiments/ENCSR000EGJ/) ENCODE experiment (2 fastq files: control & treatment), (3) download GRCh38 sequence (fasta) and annotation (GFF3) for the first chromosome from the Ensembl.\n",
        "* [2] Prepare design document and params YAML file for [this](https://nf-co.re/chipseq/2.0.0/parameters) Nextflow pipeline. Explain what parameters you used and why you had to specify them.\n",
        "* [1] Launch the pipeline and wait for its finish. Amend resources allocated for each process if needed (see Nexflow [config files](https://www.nextflow.io/docs/latest/config.html) for details).\n",
        "* [2] Analyze and decipher the generated QC report, report all major findings. Use [IGV](https://software.broadinstitute.org/software/igv/download) to inspect some of the reported peaks manually.\n",
        "\n",
        "\n",
        "**Note you will need a PC (or VM) running Linux with at least 16GB of RAM, and around 100GB of disk space to complete this HW.**\n"
      ],
      "metadata": {
        "id": "MCQ_ggjm2Dns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra points [1.5]\n",
        "\n",
        "Several separate tasks:\n",
        "* [0.5] Create a basic VM, install and configure JBrowse, and make your analysis results accessible online (e.g. bed/bigwig files). Remember to include a persistent link to the JBrowse session in the report.\n",
        "* [1] Use Nextflow (DSL2) to write a simple pipeline that takes as input a folder with fastq files, runs `fastqc` on each file, and then integrates results using `multiqc`.\n"
      ],
      "metadata": {
        "id": "V2_D_q_-2Fcf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General requirements\n",
        "\n",
        "**Works that fail to follow the below requirements won't be graded.**\n"
      ],
      "metadata": {
        "id": "HLwL-s8Poji_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to submit the homework?\n",
        "\n",
        "All homework must be submitted as a link to a public git repository (preferably GitHub/GitLab). In addition, you must complete each task in a separate branch with a particular name (see each section).\n"
      ],
      "metadata": {
        "id": "5FF6nI1Aoslb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the reporting format?\n",
        "\n",
        "Reports should be provided as markdown README files in the root folder of the git repository. Please, use markdown features to make the report easy to read, e.g., you must include code in special blocks, use headings, etc. \n",
        "\n",
        "You are strongly advised to write in English, but usage of Russian won't be penalized (except for code comments, see below). \n",
        "\n",
        "Reports should be self-contained, i.e. include all code (bash/dockerfiles/etc), explanations, and illustrations (e.g. screenshots). Ideally, to evaluate your assignment and reproduce results, I would only need the README file and nothing else.\n",
        "\n",
        "It is a must to comment your code and explain what is happening in each code block. You must write code comments in English. "
      ],
      "metadata": {
        "id": "eHk8RyUErT2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resources"
      ],
      "metadata": {
        "id": "SrCQrX1svRf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Git immersion](http://gitimmersion.com/) - a popular git course"
      ],
      "metadata": {
        "id": "Rr8yuVHcvVe8"
      }
    }
  ]
}